{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:12.912640Z",
     "start_time": "2022-11-23T02:54:10.575820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('mnist_train.csv')\n",
    "test_data = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:13.203693Z",
     "start_time": "2022-11-23T02:54:13.063331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(['label'], axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop(['label'], axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:13.858862Z",
     "start_time": "2022-11-23T02:54:13.461115Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class FC_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC_NN, self).__init__()\n",
    "        self.input_layer = nn.Linear(784, 128) # input_node, output_node\n",
    "        self.hidden_layer = nn.Linear(128, 10) # input_node, output_node\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = F.relu(x)\n",
    "        output = self.hidden_layer(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "torch_model = FC_NN()\n",
    "loss_fn = nn.CrossEntropyLoss() # softmax 포함\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.01)\n",
    "\n",
    "torch_x_train = torch.FloatTensor(X_train.values)\n",
    "torch_y_train = torch.FloatTensor(y_train.values).long()\n",
    "torch_x_test = torch.FloatTensor(X_test.values)\n",
    "torch_y_test = torch.FloatTensor(y_test.values).long()\n",
    "\n",
    "torch_train = TensorDataset(torch_x_train, torch_y_train)\n",
    "torch_test = TensorDataset(torch_x_test, torch_y_test)\n",
    "\n",
    "torch_train_loader = DataLoader(dataset=torch_train, batch_size = 64, shuffle=True)\n",
    "torch_test_loader = DataLoader(dataset=torch_test, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:14.085433Z",
     "start_time": "2022-11-23T02:54:14.083708Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch_model.train()\n",
    "# n_epochs = 20\n",
    "# i = 1\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#     avg_loss = 0\n",
    "#     total_batch = len(torch_train_loader)\n",
    "    \n",
    "#     for data, targets in torch_train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         x = data.view(-1, 784)\n",
    "#         prediction = torch_model(x)\n",
    "#         loss = loss_fn(prediction, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         avg_loss += loss / total_batch\n",
    "    \n",
    "#     print(f\"Epoch: {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "# print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:14.318587Z",
     "start_time": "2022-11-23T02:54:14.316991Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch_model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     for data, targets in torch_train_loader:\n",
    "#         x = data.view(-1, 784)\n",
    "#         prediction = torch_model(x)\n",
    "#         output, predicted = torch.max(prediction, 1)\n",
    "#         correct += predicted.eq(targets).sum()\n",
    "#     data_num = len(torch_train_loader.dataset)\n",
    "#     print(f\"accuracy: {correct / data_num : .4f}\")\n",
    "    \n",
    "#     correct = 0\n",
    "#     for data, targets in torch_test_loader:\n",
    "#         x = data.view(-1, 784)\n",
    "#         prediction = torch_model(x)\n",
    "#         output, predicted = torch.max(prediction, 1)\n",
    "#         correct += predicted.eq(targets).sum()\n",
    "#     data_num = len(torch_test_loader.dataset)\n",
    "#     print(f\"val_accuracy: {correct / data_num : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T02:54:14.559073Z",
     "start_time": "2022-11-23T02:54:14.557186Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_shape=(784,), activation='relu'))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T03:00:05.119563Z",
     "start_time": "2022-11-23T03:00:05.103725Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def Torch_version(batch_size, epoch):\n",
    "    torch_model = FC_NN()\n",
    "    loss_fn = nn.CrossEntropyLoss() # softmax 포함\n",
    "    optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.01)\n",
    "    torch_train_loader = DataLoader(dataset=torch_train, batch_size = batch_size)\n",
    "    torch_test_loader = DataLoader(dataset=torch_test, batch_size = batch_size)\n",
    "    \n",
    "    torch_model.train()\n",
    "    n_epochs = epoch\n",
    "    i = 1\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        avg_loss = 0\n",
    "        total_batch = len(torch_train_loader)\n",
    "\n",
    "        for data, targets in torch_train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = data.view(-1, 784)\n",
    "            prediction = torch_model(x)\n",
    "            loss = loss_fn(prediction, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss / total_batch\n",
    "            \n",
    "    torch_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct_train = 0; correct_test = 0\n",
    "        for data, targets in torch_train_loader:\n",
    "            x = data.view(-1, 784)\n",
    "            prediction = torch_model(x)\n",
    "            output, predicted = torch.max(prediction, 1)\n",
    "            correct_train += predicted.eq(targets).sum()\n",
    "        data_num_train = len(torch_train_loader.dataset)\n",
    "\n",
    "        correct = 0\n",
    "        for data, targets in torch_test_loader:\n",
    "            x = data.view(-1, 784)\n",
    "            prediction = torch_model(x)\n",
    "            output, predicted = torch.max(prediction, 1)\n",
    "            correct_test += predicted.eq(targets).sum()\n",
    "        data_num_test = len(torch_test_loader.dataset)\n",
    "        \n",
    "    return avg_loss, correct_train / data_num_train, correct_test / data_num_test\n",
    "\n",
    "def Torch_version_only_train(batch_size, epoch):\n",
    "    torch_model = FC_NN()\n",
    "    loss_fn = nn.CrossEntropyLoss() # softmax 포함\n",
    "    optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.01)\n",
    "    torch_model.train()\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        avg_loss = 0\n",
    "        total_batch = len(torch_train_loader)\n",
    "\n",
    "        for data, targets in torch_train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = data.view(-1, 784)\n",
    "            prediction = torch_model(x)\n",
    "            loss = loss_fn(prediction, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    return avg_loss, 0, 0\n",
    "\n",
    "def Tensor_version(batch_size, epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(784,), activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epoch, batch_size=batch_size, verbose=False)\n",
    "    \n",
    "    return history.history['loss'][-1], history.history['accuracy'][-1], history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T03:13:19.554957Z",
     "start_time": "2022-11-23T03:11:40.593588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Tenflow 1 | time: 19.8539 | loss: 0.0608 | acc: 0.9877 | val_acc: 0.9679 |\n",
      "| Tenflow 2 | time: 19.7092 | loss: 0.0540 | acc: 0.9885 | val_acc: 0.9720 |\n",
      "| Tenflow 3 | time: 19.7319 | loss: 0.0522 | acc: 0.9889 | val_acc: 0.9688 |\n",
      "| Tenflow 4 | time: 19.7392 | loss: 0.0538 | acc: 0.9887 | val_acc: 0.9664 |\n",
      "| Tenflow 5 | time: 19.9213 | loss: 0.0523 | acc: 0.9890 | val_acc: 0.9721 |\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(1,6):\n",
    "    start = time.time()\n",
    "    loss, acc, val_acc = Tensor_version(64, 20)\n",
    "    end = time.time()\n",
    "    print(f\"| Tenflow {i} | time: {end-start:.4f} | loss: {loss:.4f} | acc: {acc:.4f} | val_acc: {val_acc:.4f} |\")\n",
    "#     start = time.time()\n",
    "#     loss, acc, val_acc = Torch_version(64, 20)\n",
    "#     end = time.time()\n",
    "#     print(f\"| PyTorch {i} | time: {end-start:.4f} | loss: {loss:.4f} | acc: {acc:.4f} | val_acc: {val_acc:.4f} |\")\n",
    "#     start = time.time()\n",
    "#     loss, acc, val_acc = Torch_version_only_train(64, 20)\n",
    "#     end = time.time()\n",
    "#     print(f\"| Torchot {i} | time: {end-start:.4f} | loss: {loss:.4f} | acc: {acc:.4f} | val_acc: {val_acc:.4f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
